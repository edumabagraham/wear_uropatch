{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                        roc_curve, auc, roc_auc_score, log_loss)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/pipeline/data_extracted_features/two_class_pp_5s_0.5.csv\"\n",
    "features = pd.read_csv(data_path)\n",
    "features.drop(columns=['center_time', 'start_time', 'end_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.drop(columns=['label', 'experiment_id'])\n",
    "y = features['label']\n",
    "groups = features['experiment_id']\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac686879",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                    'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4477759",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028370c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(\n",
    "#     n_estimators=284,\n",
    "#     max_depth=9,\n",
    "#     learning_rate=0.03730930,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.7,\n",
    "#     min_child_weight=5,\n",
    "#     gamma=3.6165,\n",
    "#     reg_alpha=1.5085,\n",
    "#     reg_lambda=1.29783,\n",
    "# )\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=261,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.03730930294,\n",
    "    subsample=0.7771428924,\n",
    "    colsample_bytree=0.6888112622,\n",
    "    min_child_weight=5,\n",
    "    gamma=3.616516149,\n",
    "    reg_alpha=1.508519683,\n",
    "    reg_lambda=1.297827645,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = select_feature.transform(X_train)\n",
    "X_test_selected = select_feature.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afede3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad33ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = ['non-void', 'void']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['non-void', 'void']\n",
    "# y_pred = label_encoder.inverse_transform(model.predict(X_test_selected))\n",
    "y_pred = model.predict(X_test_selected)\n",
    "y_pred_prob = model.predict_proba(X_test_selected)\n",
    "y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred_prob, axis=1))\n",
    "report = classification_report(y_test, y_pred, labels=[0, 1], target_names=classes)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ordered = ['void', 'non-void']\n",
    "# Confusion matrix with void on top\n",
    "cm = confusion_matrix(y_test, y_pred)  # [void, non-void]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb98ba",
   "metadata": {},
   "source": [
    "## Overlay predictions on original plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e60cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/df_dict_imu.pkl', 'rb') as f:\n",
    "    imu_dict = pickle.load(f)\n",
    "with open('../data/df_dict_urineestimate_method1.pkl', 'rb') as f:\n",
    "    urine_estimates_dict = pickle.load(f)\n",
    "with open('../data/df_minze_dict.pkl', 'rb') as f:\n",
    "    ground_truth_dict = pickle.load(f)\n",
    "    \n",
    "gender = pd.read_excel('../data/demographics_uroflowmetry.xlsx', index_col=0)\n",
    "gender.drop(['Age', 'Waist Circumference (cm)', 'Height (cm)', 'Weight (Kg)', 'GD Vol (ml)', 'NOTES'], axis=1, inplace=True)\n",
    "sex = gender['Gender']\n",
    "sex = np.array(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "voids = {\n",
    "    'subj_1_void7': 5, \n",
    "    'subj_2_void2': 9,\n",
    "    'subj_2_void7': 14,\n",
    "    'subj_3_void8': 20,\n",
    "    'subj_5_void2': 25,\n",
    "    'subj_5_void3': 26,\n",
    "    'subj_8_void1': 30,\n",
    "    'subj_15_void1': 40,\n",
    "    'subj_16_void1': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep everything together for easier analysis\n",
    "test_results = pd.DataFrame({\n",
    "    'group': groups_test,\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/pipeline/data_extracted_features/two_class_pp_5s_0.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4354fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_timing(features_df, predicted_labels, ax_pred):\n",
    "    \"\"\"\n",
    "    Plot predictions using exact timing info from features DataFrame\n",
    "    features_df and predicted_labels are already filtered for one instance\n",
    "    \"\"\"\n",
    "    # Plot each prediction window\n",
    "    void_label_added = False\n",
    "    non_void_label_added = False\n",
    "    \n",
    "    for i, prediction in enumerate(predicted_labels):\n",
    "        # Get timing info from features (convert seconds to ms to match your time axis)\n",
    "        start_time = features_df.iloc[i]['start_time'] \n",
    "        # start_time = features_df.iloc[i]['center_time']\n",
    "        end_time = features_df.iloc[i]['end_time'] \n",
    "        \n",
    "        # Plot as colored spans\n",
    "        if prediction == 1:  # Void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightgreen')\n",
    "            void_label_added = True\n",
    "        # else:  # Non-void prediction\n",
    "        #     ax_pred.axvspan(start_time, end_time, alpha=0.4, color='lightblue')\n",
    "        #                 # label='Non-void Prediction' if not non_void_label_added else \"\")\n",
    "        #     non_void_label_added = True\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax_pred.set_ylim(0, 1)\n",
    "    ax_pred.set_ylabel('Predictions')\n",
    "    ax_pred.set_yticks([0, 1])\n",
    "    ax_pred.legend(loc='upper right')\n",
    "    \n",
    "    return ax_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i_void_instance, void_instance in enumerate(voids.keys()):\n",
    "    imu_data = imu_dict[void_instance]\n",
    "    urine_estimates = urine_estimates_dict[void_instance]\n",
    "    ground_truth = ground_truth_dict[void_instance]\n",
    "    exp_id = voids[void_instance]\n",
    "        \n",
    "    # Urination event is the first and last time of the ground truth data\n",
    "    urination_event = [ground_truth['Time'].iloc[0], ground_truth['Time'].iloc[-1]] \n",
    "\n",
    "    # Create a figure with 2 subplots (shared x-axis)\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    # --- Top subplot: Accelerometer ---\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_x'], color='0.2', label='acc_x')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_y'], color='0.5', label='acc_y')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_z'], color='0.7', label='acc_z')\n",
    "    ax_top.set_ylabel('Acceleration (m/s²)')\n",
    "    # Add title\n",
    "    ax_top.set_title(f'IMU Data with Predictions for {void_instance} - {exp_id}', fontsize=14, fontweight='bold')\n",
    "    ax_top.legend(loc='best')\n",
    "    ax_top.grid(True)\n",
    "        \n",
    "    # Add vertical lines for urination event\n",
    "    ax_top.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_top.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add phase labels at the top of the top subplot only\n",
    "    x_min, x_max = ax_top.get_xlim()\n",
    "    y_min, y_max = ax_top.get_ylim()\n",
    "\n",
    "    # Pre-void label\n",
    "    pre_void_center = (x_min + urination_event[0]) / 2\n",
    "    ax_top.text(pre_void_center, y_max * 0.95, 'Non-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "        \n",
    "    # Void label\n",
    "    void_center = (urination_event[0] + urination_event[1]) / 2\n",
    "    ax_top.text(void_center, y_max * 0.95, 'Void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
    "        \n",
    "    # Post-void label\n",
    "    post_void_center = (urination_event[1] + x_max) / 2\n",
    "    ax_top.text(post_void_center, y_max * 0.95, 'Non-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "        \n",
    "    # --- Bottom subplot: Gyroscope ---\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_x'], color='0.2', label='gyr_x', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_y'], color='0.5', label='gyr_y', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_z'], color='0.7', label='gyr_z', alpha=0.8)\n",
    "    ax_bottom.set_ylabel('Angular Velocity (rad/s)')\n",
    "    ax_bottom.set_xlabel('Time (ms)')\n",
    "    ax_bottom.legend(loc='best')\n",
    "    ax_bottom.grid(True)\n",
    "        \n",
    "    # Add vertical lines for urination event\n",
    "    ax_bottom.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_bottom.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "    # --- Overlay predictions on bottom subplot ---\n",
    "    ax_pred = ax_bottom.twinx()\n",
    "    predicted_labels = test_results[test_results['group'] == exp_id]['predicted'].tolist()\n",
    "    actual_labels = test_results[test_results['group'] == exp_id]['actual'].tolist()\n",
    "    features_df_ = features_df[features_df['experiment_id'] == exp_id]\n",
    "    print(f\"Experiment ID: {exp_id}; Instance: {void_instance}\")\n",
    "    print(predicted_labels)\n",
    "    plot_predictions_with_timing(features_df_, predicted_labels, ax_pred)\n",
    "\n",
    "\n",
    "    # Add legend that combines both axes# model.fit(X_train, y_train)\n",
    "\n",
    "    lines1, labels1 = ax_bottom.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_pred.get_legend_handles_labels()\n",
    "    ax_bottom.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "        \n",
    "        \n",
    "    # path_5s_0_5 = 'plots'\n",
    "    # # Save plot   \n",
    "    # if not os.path.exists(path_5s_0_5):\n",
    "    #     os.mkdir(path_5s_0_5)\n",
    "    #     filename = os.path.join(path_5s_0_5, f'{void_instance}_overlay.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # else:\n",
    "    #     filename = os.path.join(path_5s_0_5, f'{void_instance}_overlay.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f55e7e",
   "metadata": {},
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d302be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_df = pd.DataFrame(y_pred_prob, columns=classes)\n",
    "y_pred_prob_df['experiment_id'] = groups_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "void_probs_exp_ids = y_pred_prob_df.drop(columns=['non-void'])\n",
    "void_probs_exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1583a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "\n",
    "def implementation_2_best_seed(df, prob_col='void', id_col='experiment_id', n_states=3, seeds=range(200)):\n",
    "    # transmat = np.array([\n",
    "    #     [0.7, 0.3, 0.0],    # pre-void -> mostly stay, can go to void\n",
    "    #     [0.0, 0.90, 0.1],   # void -> mostly stay, can go to post-void\n",
    "    #     [0.0, 0.0, 1.0]     # post-void -> terminal\n",
    "    # ])\n",
    "    \n",
    "    \n",
    "    transmat = np.array([\n",
    "    [0.85, 0.15, 0.0],   # pre-void: mostly stay, can go to void\n",
    "    [0.0, 0.80, 0.20],   # void: mostly stay, can go to post-void\n",
    "    [0.0, 0.0, 1.0]    # post-void: mostly stay, can cycle back to pre-void\n",
    "])\n",
    "    \n",
    "    startprob = np.array([1.0, 0.0, 0.0])\n",
    "    \n",
    "    # Prepare combined observations once\n",
    "    all_obs = []\n",
    "    lengths = []\n",
    "    for exp_id, group in df.groupby(id_col):  # Fixed: was id*col\n",
    "        observations = (group[prob_col] >= 0.20).astype(int).to_numpy().reshape(-1, 1)\n",
    "        all_obs.append(observations)\n",
    "        lengths.append(len(observations))\n",
    "    all_obs = np.vstack(all_obs)\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    best_seed = None  # Initialize to avoid UnboundLocalError\n",
    "    \n",
    "    # Try multiple seeds and keep the best\n",
    "    for seed in seeds:\n",
    "        try:\n",
    "            model = hmm.CategoricalHMM(\n",
    "                n_components=n_states,\n",
    "                init_params=\"e\",  # only emissions will be learned\n",
    "                n_iter=100,\n",
    "                tol=1e-4,\n",
    "                random_state=seed\n",
    "            )\n",
    "            model.startprob_ = startprob\n",
    "            model.transmat_ = transmat\n",
    "            model.fit(all_obs, lengths)\n",
    "            score = model.score(all_obs, lengths)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_seed = seed\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Seed {seed} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is None:\n",
    "        raise ValueError(\"All seeds failed to converge!\")\n",
    "    \n",
    "    # Decode using the best model\n",
    "    state_map = {0: 'pre-void', 1: 'void', 2: 'post-void'}\n",
    "    all_results = []\n",
    "    \n",
    "    for exp_id, group in df.groupby(id_col):\n",
    "        observations = (group[prob_col] >= 0.20).astype(int).to_numpy().reshape(-1, 1)\n",
    "        _, hidden_states = best_model.decode(observations, algorithm=\"viterbi\")  # Fixed: was *, hidden*states\n",
    "        \n",
    "        group_result = group.copy()\n",
    "        group_result['predicted_state'] = [state_map[s] for s in hidden_states]\n",
    "        all_results.append(group_result)\n",
    "    \n",
    "    return pd.concat(all_results), best_model.emissionprob_, best_score, best_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_state_preds, best_emissionprob, best_score, best_seed = implementation_2_best_seed(void_probs_exp_ids, n_states=3, seeds=range(200))\n",
    "state_preds = best_test_state_preds['predicted_state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pred_enc = label_encoder.fit_transform(state_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pred_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b91399",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pred_enc = state_pred_enc.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['hmm_pred'] = state_pred_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ec018",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,def optimize_model(self, model_name: str, X_train, y_train, groups_train) -> Tuple[Dict, float]:\n",
    "        \"\"\"Optimize hyperparameters for a specific model using inner CV.\"\"\"\n",
    "        \n",
    "        def objective(trial):\n",
    "            params = self.get_model_search_space(model_name, trial)\n",
    "            fold_scores = []\n",
    "\n",
    "            for train_idx, val_idx in self.inner_cv.split(X_train, y_train, groups_train):\n",
    "                try:\n",
    "                    X_train_inner = X_train.iloc[train_idx]\n",
    "                    X_val_inner = X_train.iloc[val_idx]\n",
    "                    y_train_inner = y_train[train_idx]\n",
    "                    y_val_inner = y_train[val_idx]\n",
    "\n",
    "                    model = self.create_model(model_name, params)\n",
    "                    model.fit(X_train_inner, y_train_inner)\n",
    "\n",
    "                    # Get predicted probabilities for the validation set\n",
    "                    y_proba = model.predict_proba(X_val_inner)\n",
    "\n",
    "                    # Calculate negative log loss (maximize this = minimize log loss)\n",
    "                    score = -log_loss(y_val_inner, y_proba)\n",
    "                    fold_scores.append(score)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Error in inner fold for {model_name}: {e}\")\n",
    "                    # Use Optuna's pruning mechanism instead of arbitrary score\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            return np.mean(fold_scores) if fold_scores else -np.inf\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(test_results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_timing(features_df, predicted_labels, ax_pred):\n",
    "    \"\"\"\n",
    "    Plot predictions using exact timing info from features DataFrame\n",
    "    features_df and predicted_labels are already filtered for one instance\n",
    "    \"\"\"\n",
    "    # Plot each prediction window\n",
    "    void_label_added = False\n",
    "    post_void_label_added = False\n",
    "    pre_void_label_added = False\n",
    "    \n",
    "    for i, prediction in enumerate(predicted_labels):\n",
    "        # Get timing info from features (convert seconds to ms to match your time axis)\n",
    "        start_time = features_df.iloc[i]['start_time'] \n",
    "        # start_time = features_df.iloc[i]['center_time']\n",
    "        end_time = features_df.iloc[i]['end_time'] \n",
    "        \n",
    "        # Plot as colored spans\n",
    "        if prediction == 2:  # Void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightgreen')\n",
    "            void_label_added = True\n",
    "        # elif prediction == 0:  # Post void prediction\n",
    "        #     ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightcoral')\n",
    "        #     post_void_label_added = True\n",
    "        # elif prediction == 1:  # Pre void prediction\n",
    "        #     ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightblue')\n",
    "        #     pre_void_label_added = True\n",
    "\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax_pred.set_ylim(0, 1)\n",
    "    ax_pred.set_ylabel('Predictions')\n",
    "    ax_pred.set_yticks([0, 1])\n",
    "    ax_pred.legend(loc='upper right')\n",
    "    \n",
    "    return ax_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6710768",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_void_instance, void_instance in enumerate(voids.keys()):\n",
    "    imu_data = imu_dict[void_instance]\n",
    "    urine_estimates = urine_estimates_dict[void_instance]\n",
    "    ground_truth = ground_truth_dict[void_instance]\n",
    "    exp_id = voids[void_instance]\n",
    "    \n",
    "    # Urination event is the first and last time of the ground truth data\n",
    "    urination_event = [ground_truth['Time'].iloc[0], ground_truth['Time'].iloc[-1]] \n",
    "    \n",
    "    # Create a figure with 2 subplots (shared x-axis)\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # --- Top subplot: Accelerometer ---\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_x'], color='0.2', label='acc_x')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_y'], color='0.5', label='acc_y')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_z'], color='0.7', label='acc_z')\n",
    "    ax_top.set_ylabel('Acceleration (m/s²)')\n",
    "    ax_top.set_title(f'IMU Data with Predictions for {void_instance} - {exp_id}', fontsize=14, fontweight='bold')\n",
    "    ax_top.legend(loc='best')\n",
    "    ax_top.grid(True)\n",
    "    \n",
    "    # Add vertical lines for urination event\n",
    "    ax_top.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_top.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add phase labels at the top of the top subplot only\n",
    "    x_min, x_max = ax_top.get_xlim()\n",
    "    y_min, y_max = ax_top.get_ylim()\n",
    "    \n",
    "    # Pre-void label\n",
    "    pre_void_center = (x_min + urination_event[0]) / 2\n",
    "    ax_top.text(pre_void_center, y_max * 0.95, 'Pre-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    # Void label\n",
    "    void_center = (urination_event[0] + urination_event[1]) / 2\n",
    "    ax_top.text(void_center, y_max * 0.95, 'Void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    # Post-void label\n",
    "    post_void_center = (urination_event[1] + x_max) / 2\n",
    "    ax_top.text(post_void_center, y_max * 0.95, 'Post-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))\n",
    "    \n",
    "    # --- Bottom subplot: Gyroscope ---\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_x'], color='0.2', label='gyr_x', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_y'], color='0.5', label='gyr_y', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_z'], color='0.7', label='gyr_z', alpha=0.8)\n",
    "    ax_bottom.set_ylabel('Angular Velocity (rad/s)')\n",
    "    ax_bottom.set_xlabel('Time (ms)')\n",
    "    ax_bottom.legend(loc='best')\n",
    "    ax_bottom.grid(True)\n",
    "    \n",
    "    # --- Overlay predictions on bottom subplot ---\n",
    "    ax_pred = ax_bottom.twinx()\n",
    "    predicted_labels = test_results[test_results['group'] == exp_id]['hmm_pred'].tolist()\n",
    "    actual_labels = test_results[test_results['group'] == exp_id]['actual'].tolist()\n",
    "    features_df_ = features_df[features_df['experiment_id'] == exp_id]\n",
    "    print(f\"Experiment ID: {exp_id}; Instance: {void_instance}\")\n",
    "    print(predicted_labels)\n",
    "    plot_predictions_with_timing(features_df_, predicted_labels, ax_pred)\n",
    "    \n",
    "    # Add vertical lines for urination event\n",
    "    ax_bottom.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_bottom.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # # Save plot   \n",
    "    # if not os.path.exists(acc_gyr_path):\n",
    "    #     os.mkdir(acc_gyr_path)\n",
    "    #     filename = os.path.join(acc_gyr_path, f'{void_instance}_acc_gyr.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # else:\n",
    "    #     filename = os.path.join(acc_gyr_path, f'{void_instance}_acc_gyr.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # plt.close()\n",
    "    \n",
    "    \n",
    "    # path_5s_0_5 = 'plots'\n",
    "    # # Save plot   \n",
    "    # if not os.path.exists(path_5s_0_5):\n",
    "    #     os.mkdir(path_5s_0_5)\n",
    "    #     filename = os.path.join(path_5s_0_5, f'{void_instance}_overlay.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # else:\n",
    "    #     filename = os.path.join(path_5s_0_5, f'{void_instance}_overlay.png')\n",
    "    #     plt.savefig(filename)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Method 2: If windows are consecutive with known step size\n",
    "# def reconstruct_with_step(predictions, window_size, step_size, start_time=0):\n",
    "#     \"\"\"\n",
    "#     Reconstruct when you know the step size between windows\n",
    "#     \"\"\"\n",
    "#     timeline_positions = []\n",
    "#     timeline_predictions = []\n",
    "    \n",
    "#     for i, pred in enumerate(predictions):\n",
    "#         # Calculate the center time of this window\n",
    "#         window_start = start_time + (i * step_size)\n",
    "#         window_center = window_start + (window_size // 2)\n",
    "        \n",
    "#         timeline_positions.append(window_center)\n",
    "#         timeline_predictions.append(pred)\n",
    "    \n",
    "#     return pd.DataFrame({\n",
    "#         'time_position': timeline_positions,\n",
    "#         'prediction': timeline_predictions\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a238be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Reconstruct your timeline\n",
    "# timeline_df = reconstruct_with_step(predicted_labels, window_size=5, step_size=0.5)\n",
    "\n",
    "# # Plot like your diagram\n",
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# # Plot the predictions as a timeline\n",
    "# plt.step(timeline_df['time_position'], timeline_df['prediction'], \n",
    "#         where='mid', linewidth=2, label='Predicted Labels')\n",
    "\n",
    "\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Predicted Label')\n",
    "# plt.title('Timeline Reconstruction from Sliding Window Predictions')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3143de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [2,3,7,4,1,10]\n",
    "\n",
    "x = 0\n",
    "for i in arr:\n",
    "    if i >= x:\n",
    "        x = i\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc007add",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = arr[0]\n",
    "for i in arr:\n",
    "    if i <= x:\n",
    "        x = i\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4163988",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_preds = [0,1,0,0,1,2,2,2,2,2,0,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,2,2,0,0,0,1,0,0,0,2,0,0,0,0,2,2,2,2,0,1,2,0,1,0,0,0,0,0,0,0,1,0,0,2,2,2,2,2,0,0,2,2,0,0,1,1,1,0,1,1,0,1,1,1,0,0,1,0,0,0,2,2,2,2,2,2,2,1,1,1,1,1,0,1,1,1,1,1,0,0,0,0,2,2,0,2,2,2,2,2,2,0,2,2,2,2,1,1,1,0,0,0,2,2,0,1,1,2,2,2,1,2,2,2,2,2,0,0,0,1,2,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2]\n",
    "hmm_preds = test_results['hmm_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(three_preds))\n",
    "print(len(hmm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b381ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(three_preds, hmm_preds)\n",
    "report = classification_report(three_preds, hmm_preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ordered = ['void', 'non-void']\n",
    "# Confusion matrix with void on top\n",
    "cm = confusion_matrix(three_preds, hmm_preds)  # [void, non-void]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606a950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
