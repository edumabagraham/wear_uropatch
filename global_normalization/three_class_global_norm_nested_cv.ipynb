{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c098715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                        roc_curve, auc, roc_auc_score, log_loss)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from essentials import complete_preprocessing_pipeline\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "from essentials import normalization\n",
    "from feature_sets_center_less import GenerateFeatures\n",
    "from three_class_ncv_selectk_gn import ModifiedNestedCVOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/df_dict_imu.pkl', 'rb') as f:\n",
    "    imu_dict = pickle.load(f)\n",
    "with open('../data/df_dict_urineestimate_method1.pkl', 'rb') as f:\n",
    "    urine_estimates_dict = pickle.load(f)\n",
    "with open('../data/df_minze_dict.pkl', 'rb') as f:\n",
    "    ground_truth_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbb6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del imu_dict['subj_9_void4']\n",
    "del imu_dict['subj_11_void2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = copy.deepcopy(imu_dict)\n",
    "labelled_imu_dict = complete_preprocessing_pipeline(data_dict, ground_truth_dict, \n",
    "                                target_fs=60,normalize_data=False, use_three_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30149800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add experiment_id to each dataframe and append to imu_dict\n",
    "imu_list = []\n",
    "for i, key in enumerate(labelled_imu_dict.keys()):\n",
    "    df  = labelled_imu_dict[key]\n",
    "    df['experiment_id'] = i + 1\n",
    "\n",
    "    imu_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8267a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the dataframes in imu_dict into a single dataframe\n",
    "main_df = pd.concat(imu_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window configurations (same as your pipeline)\n",
    "window_configs = [\n",
    "    (1, 0.0), (1, 0.5), (1, 0.8),\n",
    "    (2, 0.0), (2, 0.5), (2, 0.8),\n",
    "    (3, 0.0), (3, 0.5), (3, 0.8),\n",
    "    (4, 0.0), (4, 0.5), (4, 0.8),\n",
    "    (5, 0.0), (5, 0.5), (5, 0.8)\n",
    "]\n",
    "\n",
    "def dataframe_to_dict_by_experiment(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Convert DataFrame to dictionary with experiment_id as key\"\"\"\n",
    "    experiment_dict = {}\n",
    "    for exp_id in df['experiment_id'].unique():\n",
    "        exp_data = df[df['experiment_id'] == exp_id].copy()\n",
    "        exp_data = exp_data.drop(columns=['experiment_id'])\n",
    "        # IMPORTANT: Reset index to avoid KeyError in feature extraction\n",
    "        exp_data = exp_data.reset_index(drop=True)\n",
    "        experiment_dict[f'exp_{exp_id}'] = exp_data\n",
    "    return experiment_dict\n",
    "\n",
    "def extract_features_from_dict(data_dict: dict, window_size: float, overlap: float) -> pd.DataFrame:\n",
    "    \"\"\"Extract features from dictionary of DataFrames\"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for exp_key, df in data_dict.items():\n",
    "        actual_exp_id = int(exp_key.split('_')[1])\n",
    "        \n",
    "        analyzer = GenerateFeatures(fs=60, window_duration=window_size, overlap=overlap)\n",
    "        features, _ = analyzer.analyze_multi_axis_imu(df)\n",
    "        \n",
    "        table = analyzer.create_summary_table()\n",
    "        table['experiment_id'] = actual_exp_id\n",
    "        all_features.append(table)\n",
    "    \n",
    "    return pd.concat(all_features, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccdf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for all window configurations\n",
    "all_global_norm_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310b7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outer_splits = 5\n",
    "n_inner_splits = 3\n",
    "\n",
    "outer_cv = StratifiedGroupKFold(n_splits=n_outer_splits, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedGroupKFold(n_splits=n_inner_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through each window configuration\n",
    "for window_size, overlap in window_configs:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING: {window_size}s window, {overlap} overlap\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    config_fold_results = []\n",
    "\n",
    "    # Split dictionary into training and testing sets based on void instances\n",
    "    for fold_id, (train_id, test_id) in enumerate(outer_cv.split(main_df, y=main_df['label'], groups=main_df['experiment_id'])):\n",
    "        print(f\"Fold {fold_id + 1}\")\n",
    "        data_train, data_test = main_df.iloc[train_id], main_df.iloc[test_id]\n",
    "        _, _ = main_df['label'].iloc[train_id], main_df['label'].iloc[test_id]\n",
    "        groups_train, groups_test = main_df['experiment_id'].iloc[train_id], main_df['experiment_id'].iloc[test_id]\n",
    "\n",
    "        \n",
    "        # Apply global normalization\n",
    "        data_train_norm, data_test_norm = normalization(data_train, data_test)\n",
    "\n",
    "        print(f\"✓ Applied global normalization\")\n",
    "        print(f\"Train experiments: {sorted(groups_train.unique())}\")\n",
    "        print(f\"Test experiments: {sorted(groups_test.unique())}\")\n",
    "    \n",
    "        # Convert normalized DataFrames to dictionaries for feature extraction\n",
    "        train_dict = dataframe_to_dict_by_experiment(data_train_norm)\n",
    "        test_dict = dataframe_to_dict_by_experiment(data_test_norm)\n",
    "        \n",
    "        # Extract features\n",
    "        print(f\"Extracting features...\")\n",
    "        train_features = extract_features_from_dict(train_dict, window_size, overlap)\n",
    "        test_features = extract_features_from_dict(test_dict, window_size, overlap)\n",
    "        \n",
    "        print(f\"Train features shape: {train_features.shape}\")\n",
    "        print(f\"Test features shape: {test_features.shape}\")\n",
    "        \n",
    "        # Store this fold's results\n",
    "        fold_result = {\n",
    "            'fold': fold_id + 1,\n",
    "            'window_size': window_size,\n",
    "            'overlap': overlap,\n",
    "            'train_features': train_features,\n",
    "            'test_features': test_features,\n",
    "            'original_train_groups': groups_train,\n",
    "            'original_test_groups': groups_test\n",
    "        }\n",
    "        config_fold_results.append(fold_result)\n",
    "        \n",
    "    # Store results for this configuration - for each window size and overlap, we get 5 fold results\n",
    "    overlap_str = 'no' if overlap == 0.0 else str(overlap)\n",
    "    config_key = f\"{window_size}s_{overlap_str}\"\n",
    "    all_global_norm_results[config_key] = config_fold_results\n",
    "    \n",
    "    print(f\"\\n✓ Completed {config_key}: {len(config_fold_results)} folds\")\n",
    "    \n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FEATURE EXTRACTION COMPLETED FOR ALL CONFIGURATIONS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Show summary\n",
    "for config_key, fold_results in all_global_norm_results.items():\n",
    "    print(f\"\\n{config_key}:\")\n",
    "    for fold_result in fold_results:\n",
    "        fold_id = fold_result['fold']\n",
    "        train_shape = fold_result['train_features'].shape\n",
    "        test_shape = fold_result['test_features'].shape\n",
    "        print(f\"  Fold {fold_result['fold']}: Train{train_shape}, Test{test_shape}\")\n",
    "        \n",
    "        # Save train and test features to CSV for inspection\n",
    "        fold_result['train_features'].to_csv(\n",
    "            f'/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/extracted_features/three_class/train_{config_key}_fold{fold_id}.csv', \n",
    "            index=False\n",
    "        )\n",
    "        fold_result['test_features'].to_csv(\n",
    "            f'/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/extracted_features/three_class/test_{config_key}_fold{fold_id}.csv', \n",
    "            index=False\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56476200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle all_global_norm_results\n",
    "with open('/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_global_norm_extracted_features.pkl', 'wb') as f:\n",
    "    pickle.dump(all_global_norm_results,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8fcbd",
   "metadata": {},
   "source": [
    "# Nested CV with pre-split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the modified optimizer\n",
    "\n",
    "# # Run the modified nested CV on your extracted features\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(\"STARTING MODIFIED NESTED CV WITH HYPERPARAMETER OPTIMIZATION\")\n",
    "# print(f\"{'='*80}\")\n",
    "\n",
    "# # Check what you have\n",
    "# print(f\"Available configurations: {list(all_global_norm_results.keys())}\")\n",
    "# print(f\"Total folds per configuration: {len(list(all_global_norm_results.values())[0])}\")\n",
    "\n",
    "# # Run the evaluation\n",
    "# detailed_results, summary_results, optimizer = run_modified_nested_cv(\n",
    "#     all_global_norm_results,\n",
    "#     positive_class=\"void\",\n",
    "#     n_inner_folds=3,  # Same as your original\n",
    "#     n_trials=50       # Same as your original\n",
    "# )\n",
    "\n",
    "# # Save detailed results\n",
    "# detailed_results.to_csv(\n",
    "#     '/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/nested_cv_results/global_norm_detailed_results.csv',\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# # Save summary results\n",
    "# summary_results.to_csv(\n",
    "#     '/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/nested_cv_results/global_norm_summary_results.csv',\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(\"RESULTS SUMMARY - AVERAGES ACROSS 5 OUTER FOLDS\")\n",
    "# print(f\"{'='*80}\")\n",
    "\n",
    "# # Verify we have 5 folds per configuration\n",
    "# folds_per_config = detailed_results.groupby(['config', 'model'])['fold'].nunique()\n",
    "# print(f\"Verification - Folds per config/model: {folds_per_config.iloc[0]} (should be 5)\")\n",
    "# print(f\"Total evaluations: {len(detailed_results)} (should be {15 * 5 * 3} = 225)\")\n",
    "\n",
    "# # Show best configurations with explicit fold averaging\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(\"TOP 10 CONFIGURATIONS (Mean ± Std across 5 folds)\")\n",
    "# print(f\"{'='*50}\")\n",
    "# top_configs = summary_results.sort_values('f1_positive_mean', ascending=False).head(10)\n",
    "\n",
    "# print(f\"{'Config':<12} {'Model':<4} {'F1(+)':<12} {'Accuracy':<12} {'AUC':<12}\")\n",
    "# print(\"-\" * 60)\n",
    "# for _, row in top_configs.iterrows():\n",
    "#     print(f\"{row['config']:<12} {row['model']:<4} \"\n",
    "#           f\"{row['f1_positive_mean']:.3f}±{row['f1_positive_std']:.3f}  \"\n",
    "#           f\"{row['accuracy_mean']:.3f}±{row['accuracy_std']:.3f}  \"\n",
    "#           f\"{row['auc_mean']:.3f}±{row['auc_std']:.3f}\")\n",
    "\n",
    "# # Show best model overall\n",
    "# best_result = summary_results.loc[summary_results['f1_positive_mean'].idxmax()]\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(\"BEST OVERALL RESULT (Mean ± Std across 5 folds)\")\n",
    "# print(f\"{'='*50}\")\n",
    "# print(f\"Configuration: {best_result['config']}\")\n",
    "# print(f\"Model: {best_result['model']}\")\n",
    "# print(f\"F1 (positive): {best_result['f1_positive_mean']:.4f} ± {best_result['f1_positive_std']:.4f}\")\n",
    "# print(f\"Accuracy: {best_result['accuracy_mean']:.4f} ± {best_result['accuracy_std']:.4f}\")\n",
    "# print(f\"AUC: {best_result['auc_mean']:.4f} ± {best_result['auc_std']:.4f}\")\n",
    "# print(f\"Precision (pos): {best_result['precision_positive_mean']:.4f} ± {best_result['precision_positive_std']:.4f}\")\n",
    "# print(f\"Recall (pos): {best_result['recall_positive_mean']:.4f} ± {best_result['recall_positive_std']:.4f}\")\n",
    "\n",
    "# # Model comparison (averaged across ALL configurations and folds)\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(\"MODEL COMPARISON (Mean ± Std across all configs & folds)\")\n",
    "# print(f\"{'='*50}\")\n",
    "# model_stats = []\n",
    "# for model in detailed_results['model'].unique():\n",
    "#     model_data = detailed_results[detailed_results['model'] == model]\n",
    "#     model_stats.append({\n",
    "#         'Model': model,\n",
    "#         'F1_Pos_Mean': model_data['f1_positive'].mean(),\n",
    "#         'F1_Pos_Std': model_data['f1_positive'].std(),\n",
    "#         'Accuracy_Mean': model_data['accuracy'].mean(),\n",
    "#         'Accuracy_Std': model_data['accuracy'].std(),\n",
    "#         'AUC_Mean': model_data['auc'].mean(),\n",
    "#         'AUC_Std': model_data['auc'].std(),\n",
    "#         'N_Evaluations': len(model_data)\n",
    "#     })\n",
    "\n",
    "# model_comparison_df = pd.DataFrame(model_stats)\n",
    "# print(model_comparison_df.round(4))\n",
    "\n",
    "# # Configuration comparison (averaged across models and folds)\n",
    "# print(f\"\\n{'='*50}\")\n",
    "# print(\"TOP 5 WINDOW CONFIGURATIONS (Mean ± Std across models & folds)\")\n",
    "# print(f\"{'='*50}\")\n",
    "# config_stats = []\n",
    "# for config in detailed_results['config'].unique():\n",
    "#     config_data = detailed_results[detailed_results['config'] == config]\n",
    "#     config_stats.append({\n",
    "#         'Config': config,\n",
    "#         'F1_Pos_Mean': config_data['f1_positive'].mean(),\n",
    "#         'F1_Pos_Std': config_data['f1_positive'].std(),\n",
    "#         'Accuracy_Mean': config_data['accuracy'].mean(),\n",
    "#         'AUC_Mean': config_data['auc'].mean(),\n",
    "#         'N_Evaluations': len(config_data)\n",
    "#     })\n",
    "\n",
    "# config_comparison_df = pd.DataFrame(config_stats).sort_values('F1_Pos_Mean', ascending=False)\n",
    "# print(config_comparison_df.head().round(4))\n",
    "\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(\"ANALYSIS COMPLETE\")\n",
    "# print(f\"Detailed results saved to: global_normalization/nested_cv_results/global_norm_detailed_results.csv\")\n",
    "# print(f\"Summary results saved to: global_normalization/nested_cv_results/global_norm_summary_results.csv\")\n",
    "# print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e69aee",
   "metadata": {},
   "source": [
    "# Nested CV with pre-split data - save each dataset separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9abc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickled results\n",
    "with open('/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_global_norm_extracted_features.pkl', 'rb') as f:\n",
    "    all_global_norm_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c33ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_global_norm_nested_cv_with_class(all_global_norm_results: Dict, base_save_path: str, \n",
    "                                        n_inner_folds: int = 3, \n",
    "                                        n_trials: int = 50) -> ModifiedNestedCVOptimizer:\n",
    "    \"\"\"\n",
    "    Convenience function to run global normalization nested CV using the class-based approach.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_global_norm_results : Dict\n",
    "        Results from your global normalization pipeline\n",
    "    base_save_path : str\n",
    "        Directory to save results\n",
    "    positive_class : str\n",
    "        Positive class label\n",
    "    n_inner_folds : int\n",
    "        Number of inner CV folds for hyperparameter optimization\n",
    "    n_trials : int\n",
    "        Number of optimization trials per model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ModifiedNestedCVOptimizer instance with all results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimizer = ModifiedNestedCVOptimizer(\n",
    "        n_inner_folds=n_inner_folds,\n",
    "        n_trials=n_trials,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Run all configurations\n",
    "    all_results = optimizer.run_all_configurations(all_global_norm_results, base_save_path)\n",
    "    \n",
    "    # Print summary\n",
    "    best_config, best_model, best_f1 = optimizer.get_best_configuration()\n",
    "    print(f\"\\nBEST OVERALL RESULT:\")\n",
    "    print(f\"Configuration: {best_config}\")\n",
    "    print(f\"Model: {best_model}\")\n",
    "    print(f\"F1 Score (positive class): {best_f1:.4f}\")\n",
    "    \n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1861927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-20 16:41:38,615] A new study created in memory with name: no-name-8b27e755-c754-4558-b35a-82a06a330fdd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GLOBAL NORMALIZATION NESTED CV - CLASS-BASED APPROACH\n",
      "Base save path: /home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/nested_cv_results/three_class\n",
      "Configurations to process: 15\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROCESSING CONFIGURATION: 1s_no\n",
      "================================================================================\n",
      "\n",
      "  OUTER FOLD 1\n",
      "  Train: (2020, 107), Test: (378, 107)\n",
      "    Optimizing RF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-20 16:41:39,918] Trial 0 finished with value: -0.6633519959316031 and parameters: {'selector__k': 21, 'selector__score_func': 'f_classif', 'clf__n_estimators': 369, 'clf__max_depth': 3, 'clf__min_samples_split': 20, 'clf__min_samples_leaf': 9, 'clf__max_features': 'sqrt', 'clf__bootstrap': False, 'clf__class_weight': None}. Best is trial 0 with value: -0.6633519959316031.\n",
      "[I 2025-09-20 16:41:40,297] Trial 1 finished with value: -0.6547456198398659 and parameters: {'selector__k': 73, 'selector__score_func': 'f_classif', 'clf__n_estimators': 70, 'clf__max_depth': 13, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 'log2', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 1 with value: -0.6547456198398659.\n",
      "[I 2025-09-20 16:41:42,446] Trial 2 finished with value: -4.734611287458243 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 133, 'clf__max_depth': 20, 'clf__min_samples_split': 16, 'clf__min_samples_leaf': 10, 'clf__max_features': None, 'clf__bootstrap': False, 'clf__class_weight': 'balanced'}. Best is trial 1 with value: -0.6547456198398659.\n",
      "[I 2025-09-20 16:41:44,618] Trial 3 finished with value: -0.6210400224959283 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 495, 'clf__max_depth': 16, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:45,759] Trial 4 finished with value: -0.7197655888593023 and parameters: {'selector__k': 'all', 'selector__score_func': 'f_classif', 'clf__n_estimators': 262, 'clf__max_depth': 5, 'clf__min_samples_split': 15, 'clf__min_samples_leaf': 8, 'clf__max_features': 'log2', 'clf__bootstrap': True, 'clf__class_weight': 'balanced'}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:46,830] Trial 5 finished with value: -1.0091829231102256 and parameters: {'selector__k': 52, 'selector__score_func': 'f_classif', 'clf__n_estimators': 84, 'clf__max_depth': 8, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 10, 'clf__max_features': None, 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:48,039] Trial 6 finished with value: -0.7272063317536729 and parameters: {'selector__k': 21, 'selector__score_func': 'f_classif', 'clf__n_estimators': 280, 'clf__max_depth': 10, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 2, 'clf__max_features': 'log2', 'clf__bootstrap': False, 'clf__class_weight': 'balanced'}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:48,747] Trial 7 finished with value: -1.214201945817852 and parameters: {'selector__k': 10, 'selector__score_func': 'f_classif', 'clf__n_estimators': 175, 'clf__max_depth': 19, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 2, 'clf__max_features': 'log2', 'clf__bootstrap': False, 'clf__class_weight': 'balanced'}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:50,242] Trial 8 finished with value: -0.631571101898448 and parameters: {'selector__k': 73, 'selector__score_func': 'f_classif', 'clf__n_estimators': 316, 'clf__max_depth': 15, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 6, 'clf__max_features': 'log2', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:50,851] Trial 9 finished with value: -0.6332788317998991 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 159, 'clf__max_depth': 4, 'clf__min_samples_split': 19, 'clf__min_samples_leaf': 10, 'clf__max_features': 'sqrt', 'clf__bootstrap': False, 'clf__class_weight': None}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:53,280] Trial 10 finished with value: -0.6339333157804542 and parameters: {'selector__k': 94, 'selector__score_func': 'f_classif', 'clf__n_estimators': 470, 'clf__max_depth': 17, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 3 with value: -0.6210400224959283.\n",
      "[I 2025-09-20 16:41:55,456] Trial 11 finished with value: -0.6038187834376522 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 496, 'clf__max_depth': 15, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 6, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 11 with value: -0.6038187834376522.\n",
      "[I 2025-09-20 16:41:57,634] Trial 12 finished with value: -0.6039941834032941 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 500, 'clf__max_depth': 14, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 6, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 11 with value: -0.6038187834376522.\n",
      "[I 2025-09-20 16:41:59,419] Trial 13 finished with value: -0.6127856974708613 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 400, 'clf__max_depth': 12, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 6, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 11 with value: -0.6038187834376522.\n",
      "[I 2025-09-20 16:42:01,665] Trial 14 finished with value: -0.6269221021097844 and parameters: {'selector__k': 84, 'selector__score_func': 'f_classif', 'clf__n_estimators': 430, 'clf__max_depth': 14, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 11 with value: -0.6038187834376522.\n",
      "[I 2025-09-20 16:42:03,593] Trial 15 finished with value: -0.6036654062940078 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 443, 'clf__max_depth': 10, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 7, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 15 with value: -0.6036654062940078.\n",
      "[I 2025-09-20 16:42:06,467] Trial 16 finished with value: -0.8971422580987634 and parameters: {'selector__k': 31, 'selector__score_func': 'f_classif', 'clf__n_estimators': 344, 'clf__max_depth': 9, 'clf__min_samples_split': 13, 'clf__min_samples_leaf': 8, 'clf__max_features': None, 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 15 with value: -0.6036654062940078.\n",
      "[I 2025-09-20 16:42:08,206] Trial 17 finished with value: -0.7885238856165473 and parameters: {'selector__k': 10, 'selector__score_func': 'f_classif', 'clf__n_estimators': 428, 'clf__max_depth': 7, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 7, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 15 with value: -0.6036654062940078.\n",
      "[I 2025-09-20 16:42:09,585] Trial 18 finished with value: -0.6420416357523857 and parameters: {'selector__k': 'all', 'selector__score_func': 'f_classif', 'clf__n_estimators': 244, 'clf__max_depth': 11, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': 'balanced'}. Best is trial 15 with value: -0.6036654062940078.\n",
      "[I 2025-09-20 16:42:11,741] Trial 19 finished with value: -0.6035405747092245 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 446, 'clf__max_depth': 17, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 5, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 19 with value: -0.6035405747092245.\n",
      "[I 2025-09-20 16:42:16,853] Trial 20 finished with value: -0.9153960294563888 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 425, 'clf__max_depth': 18, 'clf__min_samples_split': 13, 'clf__min_samples_leaf': 5, 'clf__max_features': None, 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 19 with value: -0.6035405747092245.\n",
      "[I 2025-09-20 16:42:18,941] Trial 21 finished with value: -0.6025678646201399 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 456, 'clf__max_depth': 16, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 7, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 21 with value: -0.6025678646201399.\n",
      "[I 2025-09-20 16:42:20,729] Trial 22 finished with value: -0.6032536312685574 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 382, 'clf__max_depth': 17, 'clf__min_samples_split': 8, 'clf__min_samples_leaf': 8, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 21 with value: -0.6025678646201399.\n",
      "[I 2025-09-20 16:42:22,500] Trial 23 finished with value: -0.6037708060026178 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 379, 'clf__max_depth': 17, 'clf__min_samples_split': 12, 'clf__min_samples_leaf': 8, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 21 with value: -0.6025678646201399.\n",
      "[I 2025-09-20 16:42:24,088] Trial 24 finished with value: -0.6049541223929217 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 331, 'clf__max_depth': 20, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 7, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 21 with value: -0.6025678646201399.\n",
      "[I 2025-09-20 16:42:26,269] Trial 25 finished with value: -0.6036191097776687 and parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 454, 'clf__max_depth': 18, 'clf__min_samples_split': 7, 'clf__min_samples_leaf': 5, 'clf__max_features': 'sqrt', 'clf__bootstrap': True, 'clf__class_weight': None}. Best is trial 21 with value: -0.6025678646201399.\n",
      "[W 2025-09-20 16:42:28,109] Trial 26 failed with parameters: {'selector__k': 42, 'selector__score_func': 'f_classif', 'clf__n_estimators': 398, 'clf__max_depth': 16, 'clf__min_samples_split': 9, 'clf__min_samples_leaf': 9, 'clf__max_features': 'sqrt', 'clf__bootstrap': False, 'clf__class_weight': 'balanced'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py\", line 220, in objective\n",
      "    def calculate_comprehensive_metrics(self, y_true, y_pred, y_proba) -> Dict[str, float]:\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 905, in predict_proba\n",
      "    return self.steps[-1][1].predict_proba(Xt, **params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 956, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 2072, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1682, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1800, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-20 16:42:28,115] Trial 26 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m base_save_path = \u001b[33m'\u001b[39m\u001b[33m/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/nested_cv_results/three_class\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Run everything with one function call\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m optimizer = \u001b[43mrun_global_norm_nested_cv_with_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mall_global_norm_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_inner_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Then analyze results easily:\u001b[39;00m\n\u001b[32m     13\u001b[39m best_config, best_model, best_f1 = optimizer.get_best_configuration()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mrun_global_norm_nested_cv_with_class\u001b[39m\u001b[34m(all_global_norm_results, base_save_path, n_inner_folds, n_trials)\u001b[39m\n\u001b[32m     26\u001b[39m optimizer = ModifiedNestedCVOptimizer(\n\u001b[32m     27\u001b[39m     n_inner_folds=n_inner_folds,\n\u001b[32m     28\u001b[39m     n_trials=n_trials,\n\u001b[32m     29\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Run all configurations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m all_results = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_all_configurations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_global_norm_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n\u001b[32m     36\u001b[39m best_config, best_model, best_f1 = optimizer.get_best_configuration()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py:569\u001b[39m, in \u001b[36mrun_all_configurations\u001b[39m\u001b[34m(self, all_global_norm_results, base_save_path)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_all_configurations\u001b[39m(\u001b[38;5;28mself\u001b[39m, all_global_norm_results: Dict, base_save_path: \u001b[38;5;28mstr\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, pd.DataFrame]:\n\u001b[32m    564\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[33;03m    Run nested CV for all configurations and save results.\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[33;03m    -----------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[33;03m    all_global_norm_results : Dict\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03m        Dictionary from your global normalization pipeline\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m    base_save_path : str\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[33;03m        Base directory for saving results\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[33;03m        \u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[33;03m    --------\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[33;03m    Dict containing results for all configurations\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    579\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    580\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGLOBAL NORMALIZATION NESTED CV - CLASS-BASED APPROACH\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py:388\u001b[39m, in \u001b[36mevaluate_configuration\u001b[39m\u001b[34m(self, config_key, fold_results)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py:302\u001b[39m, in \u001b[36mevaluate_single_fold\u001b[39m\u001b[34m(self, fold_data)\u001b[39m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(fold_scores) \u001b[38;5;28;01mif\u001b[39;00m fold_scores \u001b[38;5;28;01melse\u001b[39;00m -np.inf\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Create study for this model with proper seeding\u001b[39;00m\n\u001b[32m    299\u001b[39m study = optuna.create_study(\n\u001b[32m    300\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    301\u001b[39m     sampler=optuna.samplers.TPESampler(\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m         seed=\u001b[38;5;28mself\u001b[39m.random_state,\n\u001b[32m    303\u001b[39m         n_startup_trials=\u001b[32m10\u001b[39m,\n\u001b[32m    304\u001b[39m         n_ei_candidates=\u001b[32m24\u001b[39m\n\u001b[32m    305\u001b[39m     ),\n\u001b[32m    306\u001b[39m     pruner=optuna.pruners.MedianPruner(\n\u001b[32m    307\u001b[39m         n_startup_trials=\u001b[32m10\u001b[39m,\n\u001b[32m    308\u001b[39m         n_warmup_steps=\u001b[32m5\u001b[39m,\n\u001b[32m    309\u001b[39m         n_min_trials=\u001b[32m1\u001b[39m\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m )\n\u001b[32m    313\u001b[39m study.optimize(objective, n_trials=\u001b[38;5;28mself\u001b[39m.n_trials, show_progress_bar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study.best_params, study.best_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py:246\u001b[39m, in \u001b[36moptimize_model\u001b[39m\u001b[34m(self, model_name, X_train, y_train, groups_train)\u001b[39m\n\u001b[32m    244\u001b[39m     metrics[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mprecision_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = precision_per_class[encoded_idx]\n\u001b[32m    245\u001b[39m     metrics[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecall_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = recall_per_class[encoded_idx]\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     metrics[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mf1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = f1_per_class[encoded_idx]\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# Handle cases where a class might not be present in this fold\u001b[39;00m\n\u001b[32m    249\u001b[39m     metrics[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mprecision_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/three_class_ncv_selectk_gn.py:220\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    216\u001b[39m             auc_data[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mauc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = \u001b[32m0.0\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m auc_data\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_comprehensive_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, y_proba) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    221\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculate comprehensive binary classification metrics exactly like your original.\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:905\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    904\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[32m    908\u001b[39m routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:956\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    951\u001b[39m all_proba = [\n\u001b[32m    952\u001b[39m     np.zeros((X.shape[\u001b[32m0\u001b[39m], j), dtype=np.float64)\n\u001b[32m    953\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np.atleast_1d(\u001b[38;5;28mself\u001b[39m.n_classes_)\n\u001b[32m    954\u001b[39m ]\n\u001b[32m    955\u001b[39m lock = threading.Lock()\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[32m    962\u001b[39m     proba /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Public/MPhil_Thesis/Code/wear_uropatch/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Simple usage in your notebook:\n",
    "base_save_path = '/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/global_normalization/nested_cv_results/three_class'\n",
    "\n",
    "# Run everything with one function call\n",
    "optimizer = run_global_norm_nested_cv_with_class(\n",
    "    all_global_norm_results,\n",
    "    base_save_path,\n",
    "    n_inner_folds=3,\n",
    "    n_trials=50\n",
    ")\n",
    "\n",
    "# Then analyze results easily:\n",
    "best_config, best_model, best_f1 = optimizer.get_best_configuration()\n",
    "print(f\"Best: {best_config} with {best_model} - F1: {best_f1:.4f}\")\n",
    "\n",
    "# Compare specific configurations\n",
    "comparison = optimizer.compare_configurations(['1s_0.5', '2s_0.5', '3s_0.5'])\n",
    "print(comparison)\n",
    "\n",
    "# Get detailed summary for best configuration\n",
    "summary = optimizer.get_configuration_summary(best_config)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8ebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
