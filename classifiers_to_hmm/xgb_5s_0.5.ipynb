{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                        roc_curve, auc, roc_auc_score, log_loss)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/pipeline/data_extracted_features/two_class_pp_5s_0.5.csv\"\n",
    "three_class_data_path = \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/pipeline/data_extracted_features/three_class_pp_5s_0.5.csv\"\n",
    "features = pd.read_csv(data_path)\n",
    "features.drop(columns=['center_time', 'start_time', 'end_time'], inplace=True)\n",
    "\n",
    "#Three class\n",
    "three_class_features = pd.read_csv(three_class_data_path)\n",
    "three_class_features.drop(columns=['center_time', 'start_time', 'end_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.drop(columns=['label', 'experiment_id'])\n",
    "y = features['label']\n",
    "groups = features['experiment_id']\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three class\n",
    "three_class_X = three_class_features.drop(columns=['label', 'experiment_id'])\n",
    "three_class_y = three_class_features['label']\n",
    "three_class_groups = three_class_features['experiment_id']\n",
    "\n",
    "three_class_splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "three_class_train_idx, three_class_test_idx = next(three_class_splitter.split(three_class_X, three_class_y, three_class_groups))\n",
    "\n",
    "three_class_X_train, three_class_X_test = three_class_X.iloc[three_class_train_idx], three_class_X.iloc[three_class_test_idx]\n",
    "three_class_y_train, three_class_y_test = three_class_y.iloc[three_class_train_idx], three_class_y.iloc[three_class_test_idx]\n",
    "three_class_groups_train, three_class_groups_test = three_class_groups.iloc[three_class_train_idx], groups.iloc[three_class_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac686879",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_feature = SelectKBest(f_classif, k=20).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                    'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4477759",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028370c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=261,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.03730930294,\n",
    "    subsample=0.7771428924,\n",
    "    colsample_bytree=0.6888112622,\n",
    "    min_child_weight=5,\n",
    "    gamma=3.616516149,\n",
    "    reg_alpha=1.508519683,\n",
    "    reg_lambda=1.297827645,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = select_feature.transform(X_train)\n",
    "X_test_selected = select_feature.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afede3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['void', 'non-void']\n",
    "y_pred = model.predict(X_test_selected)\n",
    "y_pred_prob = model.predict_proba(X_test_selected)\n",
    "\n",
    "\n",
    "# Convert back to original labels for the report\n",
    "y_test_original = label_encoder.inverse_transform(y_test)\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "\n",
    "# Generate classification report with actual label names\n",
    "report = classification_report(y_test_original, y_pred_original, labels=classes, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "cm = confusion_matrix(y_test_original, y_pred_original, labels=classes)  # [void, non-void]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb98ba",
   "metadata": {},
   "source": [
    "## Overlay predictions on original plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/df_dict_imu.pkl', 'rb') as f:\n",
    "    imu_dict = pickle.load(f)\n",
    "with open('../data/df_dict_urineestimate_method1.pkl', 'rb') as f:\n",
    "    urine_estimates_dict = pickle.load(f)\n",
    "with open('../data/df_minze_dict.pkl', 'rb') as f:\n",
    "    ground_truth_dict = pickle.load(f)\n",
    "    \n",
    "gender = pd.read_excel('../data/demographics_uroflowmetry.xlsx', index_col=0)\n",
    "gender.drop(['Age', 'Waist Circumference (cm)', 'Height (cm)', 'Weight (Kg)', 'GD Vol (ml)', 'NOTES'], axis=1, inplace=True)\n",
    "sex = gender['Gender']\n",
    "sex = np.array(sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3581565",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/pipeline/data_extracted_features/two_class_pp_5s_0.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "voids = {\n",
    "    'subj_1_void7': 5, \n",
    "    'subj_2_void2': 9,\n",
    "    'subj_2_void7': 14,\n",
    "    'subj_3_void8': 20,\n",
    "    'subj_5_void2': 25,\n",
    "    'subj_5_void3': 26,\n",
    "    'subj_8_void1': 30,\n",
    "    'subj_15_void1': 40,\n",
    "    'subj_16_void1': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep everything together for easier analysis\n",
    "# ==========================================================================================\n",
    "# Dataframe containing test set information\n",
    "# groups: ids of data in the two and three class test set\n",
    "# y_test: true labels of the test set of the two class data\n",
    "# y_pred: predicted labels from the classifier\n",
    "# three_class_actual: true labels of the test set of the three class data \n",
    "# ==========================================================================================\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'group': groups_test,\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred,\n",
    "    'three_class_actual': three_class_y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4354fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_timing(features_df, predicted_labels, ax_pred):\n",
    "    \"\"\"\n",
    "    Plot predictions using exact timing info from features DataFrame\n",
    "    features_df and predicted_labels are already filtered for one instance\n",
    "    \"\"\"\n",
    "    # Plot each prediction window\n",
    "    void_label_added = False\n",
    "    non_void_label_added = False\n",
    "    \n",
    "    for i, prediction in enumerate(predicted_labels):\n",
    "        # Get timing info from features (convert seconds to ms to match your time axis)\n",
    "        start_time = features_df.iloc[i]['start_time'] \n",
    "        # start_time = features_df.iloc[i]['center_time']\n",
    "        end_time = features_df.iloc[i]['end_time'] \n",
    "        \n",
    "        # Plot as colored spans\n",
    "        if prediction == 1:  # Void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightgreen')\n",
    "            void_label_added = True\n",
    "        else:  # Non-void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.4, color='lightblue')\n",
    "                        # label='Non-void Prediction' if not non_void_label_added else \"\")\n",
    "            non_void_label_added = True\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax_pred.set_ylim(0, 1)\n",
    "    ax_pred.set_ylabel('Predictions')\n",
    "    ax_pred.set_yticks([0, 1])\n",
    "    ax_pred.legend(loc='upper right')\n",
    "    \n",
    "    return ax_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i_void_instance, void_instance in enumerate(voids.keys()):\n",
    "    imu_data = imu_dict[void_instance]\n",
    "    urine_estimates = urine_estimates_dict[void_instance]\n",
    "    ground_truth = ground_truth_dict[void_instance]\n",
    "    exp_id = voids[void_instance]\n",
    "        \n",
    "    # Urination event is the first and last time of the ground truth data\n",
    "    urination_event = [ground_truth['Time'].iloc[0], ground_truth['Time'].iloc[-1]] \n",
    "\n",
    "    # Create a figure with 2 subplots (shared x-axis)\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    # --- Top subplot: Accelerometer ---\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_x'], color='0.2', label='acc_x')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_y'], color='0.5', label='acc_y')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_z'], color='0.7', label='acc_z')\n",
    "    ax_top.set_ylabel('Acceleration (m/s²)')\n",
    "    # Add title\n",
    "    ax_top.set_title(f'IMU Data with Predictions for {void_instance} - {exp_id}', fontsize=14, fontweight='bold')\n",
    "    ax_top.legend(loc='best')\n",
    "    ax_top.grid(True)\n",
    "        \n",
    "    # Add vertical lines for urination event\n",
    "    ax_top.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_top.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add phase labels at the top of the top subplot only\n",
    "    x_min, x_max = ax_top.get_xlim()\n",
    "    y_min, y_max = ax_top.get_ylim()\n",
    "\n",
    "    # Pre-void label\n",
    "    pre_void_center = (x_min + urination_event[0]) / 2\n",
    "    ax_top.text(pre_void_center, y_max * 0.95, 'Non-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "        \n",
    "    # Void label\n",
    "    void_center = (urination_event[0] + urination_event[1]) / 2\n",
    "    ax_top.text(void_center, y_max * 0.95, 'Void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
    "        \n",
    "    # Post-void label\n",
    "    post_void_center = (urination_event[1] + x_max) / 2\n",
    "    ax_top.text(post_void_center, y_max * 0.95, 'Non-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "        \n",
    "    # --- Bottom subplot: Gyroscope ---\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_x'], color='0.2', label='gyr_x', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_y'], color='0.5', label='gyr_y', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_z'], color='0.7', label='gyr_z', alpha=0.8)\n",
    "    ax_bottom.set_ylabel('Angular Velocity (rad/s)')\n",
    "    ax_bottom.set_xlabel('Time (ms)')\n",
    "    ax_bottom.legend(loc='best')\n",
    "    ax_bottom.grid(True)\n",
    "        \n",
    "    # Add vertical lines for urination event\n",
    "    ax_bottom.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_bottom.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "    # --- Overlay predictions on bottom subplot ---\n",
    "    ax_pred = ax_bottom.twinx()\n",
    "    predicted_labels = test_results[test_results['group'] == exp_id]['predicted'].tolist()\n",
    "    actual_labels = test_results[test_results['group'] == exp_id]['actual'].tolist()\n",
    "    features_df_ = features_df[features_df['experiment_id'] == exp_id]\n",
    "    print(f\"Experiment ID: {exp_id}; Instance: {void_instance}\")\n",
    "    print(predicted_labels)\n",
    "    plot_predictions_with_timing(features_df_, predicted_labels, ax_pred)\n",
    "\n",
    "\n",
    "    # Add legend that combines both axes# model.fit(X_train, y_train)\n",
    "\n",
    "    lines1, labels1 = ax_bottom.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_pred.get_legend_handles_labels()\n",
    "    ax_bottom.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "        \n",
    "        \n",
    "    path = '/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/classifiers_to_hmm/plots/xgb_5s_0.5/two'\n",
    "    # Save plot   \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        filename = os.path.join(path, f'{void_instance}({voids[void_instance]})_overlay.png')\n",
    "        plt.savefig(filename)\n",
    "    else:\n",
    "        filename = os.path.join(path, f'{void_instance}({voids[void_instance]})_overlay.png')\n",
    "        plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f55e7e",
   "metadata": {},
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classification probabilities into dataframe\n",
    "prob_classes = ['non-void', 'void']\n",
    "y_pred_prob_df = pd.DataFrame(y_pred_prob, columns=prob_classes)\n",
    "y_pred_prob_df['experiment_id'] = groups_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a4f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "void_probs_exp_ids = y_pred_prob_df.drop(columns=['non-void'])\n",
    "void_probs_exp_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1583a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "\n",
    "def implementation_2_best_seed(df, prob_col='void', id_col='experiment_id', n_states=3, seeds=range(200)):\n",
    "    transmat = np.array([\n",
    "        [0.7, 0.3, 0.0],    # pre-void -> mostly stay, can go to void\n",
    "        [0.0, 0.70, 0.3],   # void -> mostly stay, can go to post-void\n",
    "        [0.0, 0.0, 1.0]     # post-void -> terminal\n",
    "    ])\n",
    "    \n",
    "    \n",
    "#     transmat = np.array([\n",
    "#     [0.85, 0.15, 0.0],   # pre-void: mostly stay, can go to void\n",
    "#     [0.0, 0.80, 0.20],   # void: mostly stay, can go to post-void\n",
    "#     [0.0, 0.0, 1.0]    # post-void: mostly stay, can cycle back to pre-void\n",
    "# ])\n",
    "    \n",
    "    startprob = np.array([1.0, 0.0, 0.0])\n",
    "    \n",
    "    # Prepare combined observations once\n",
    "    all_obs = []\n",
    "    lengths = []\n",
    "    for exp_id, group in df.groupby(id_col):  # Fixed: was id*col\n",
    "        observations = (group[prob_col] >= 0.20).astype(int).to_numpy().reshape(-1, 1)\n",
    "        all_obs.append(observations)\n",
    "        lengths.append(len(observations))\n",
    "    all_obs = np.vstack(all_obs)\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_model = None\n",
    "    best_seed = None  # Initialize to avoid UnboundLocalError\n",
    "    \n",
    "    # Try multiple seeds and keep the best\n",
    "    for seed in seeds:\n",
    "        try:\n",
    "            model = hmm.CategoricalHMM(\n",
    "                n_components=n_states,\n",
    "                init_params=\"e\",  # only emissions will be learned\n",
    "                n_iter=100,\n",
    "                tol=1e-4,\n",
    "                random_state=seed\n",
    "            )\n",
    "            model.startprob_ = startprob\n",
    "            model.transmat_ = transmat\n",
    "            model.fit(all_obs, lengths)\n",
    "            score = model.score(all_obs, lengths)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_seed = seed\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Seed {seed} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is None:\n",
    "        raise ValueError(\"All seeds failed to converge!\")\n",
    "    \n",
    "    # Decode using the best model\n",
    "    state_map = {0: 'pre-void', 1: 'void', 2: 'post-void'}\n",
    "    all_results = []\n",
    "    \n",
    "    for exp_id, group in df.groupby(id_col):\n",
    "        observations = (group[prob_col] >= 0.20).astype(int).to_numpy().reshape(-1, 1)\n",
    "        _, hidden_states = best_model.decode(observations, algorithm=\"viterbi\")  # Fixed: was *, hidden*states\n",
    "        \n",
    "        group_result = group.copy()\n",
    "        group_result['predicted_state'] = [state_map[s] for s in hidden_states]\n",
    "        all_results.append(group_result)\n",
    "    \n",
    "    return pd.concat(all_results), best_model.emissionprob_, best_score, best_seed, all_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_state_preds, best_emissionprob, best_score, best_seed, observations = implementation_2_best_seed(void_probs_exp_ids, n_states=3, seeds=range(200))\n",
    "state_preds = best_test_state_preds['predicted_state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pred_enc = label_encoder.fit_transform(state_preds).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['hmm_pred'] = state_pred_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ec018",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                    'display.max_columns', None):\n",
    "    print(test_results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_timing(features_df, predicted_labels, ax_pred):\n",
    "    \"\"\"\n",
    "    Plot predictions using exact timing info from features DataFrame\n",
    "    features_df and predicted_labels are already filtered for one instance\n",
    "    \"\"\"\n",
    "    # Plot each prediction window\n",
    "    void_label_added = False\n",
    "    post_void_label_added = False\n",
    "    pre_void_label_added = False\n",
    "    \n",
    "    for i, prediction in enumerate(predicted_labels):\n",
    "        # Get timing info from features (convert seconds to ms to match your time axis)\n",
    "        start_time = features_df.iloc[i]['start_time'] \n",
    "        # start_time = features_df.iloc[i]['center_time']\n",
    "        end_time = features_df.iloc[i]['end_time'] \n",
    "        \n",
    "        # Plot as colored spans\n",
    "        if prediction == 2:  # Void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightgreen')\n",
    "            void_label_added = True\n",
    "        elif prediction == 0:  # Post void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightcoral')\n",
    "            post_void_label_added = True\n",
    "        elif prediction == 1:  # Pre void prediction\n",
    "            ax_pred.axvspan(start_time, end_time, alpha=0.7, color='lightblue')\n",
    "            pre_void_label_added = True\n",
    "\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax_pred.set_ylim(0, 1)\n",
    "    ax_pred.set_ylabel('Predictions')\n",
    "    ax_pred.set_yticks([0, 1])\n",
    "    ax_pred.legend(loc='upper right')\n",
    "    \n",
    "    return ax_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6710768",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_void_instance, void_instance in enumerate(voids.keys()):\n",
    "    imu_data = imu_dict[void_instance]\n",
    "    urine_estimates = urine_estimates_dict[void_instance]\n",
    "    ground_truth = ground_truth_dict[void_instance]\n",
    "    exp_id = voids[void_instance]\n",
    "    \n",
    "    # Urination event is the first and last time of the ground truth data\n",
    "    urination_event = [ground_truth['Time'].iloc[0], ground_truth['Time'].iloc[-1]] \n",
    "    \n",
    "    # Create a figure with 2 subplots (shared x-axis)\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # --- Top subplot: Accelerometer ---\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_x'], color='0.2', label='acc_x')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_y'], color='0.5', label='acc_y')\n",
    "    ax_top.plot(imu_data['time'], imu_data['acc_z'], color='0.7', label='acc_z')\n",
    "    ax_top.set_ylabel('Acceleration (m/s²)')\n",
    "    ax_top.set_title(f'IMU Data with Predictions for {void_instance} - {exp_id}', fontsize=14, fontweight='bold')\n",
    "    ax_top.legend(loc='best')\n",
    "    ax_top.grid(True)\n",
    "    \n",
    "    # Add vertical lines for urination event\n",
    "    ax_top.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_top.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add phase labels at the top of the top subplot only\n",
    "    x_min, x_max = ax_top.get_xlim()\n",
    "    y_min, y_max = ax_top.get_ylim()\n",
    "    \n",
    "    # Pre-void label\n",
    "    pre_void_center = (x_min + urination_event[0]) / 2\n",
    "    ax_top.text(pre_void_center, y_max * 0.95, 'Pre-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    # Void label\n",
    "    void_center = (urination_event[0] + urination_event[1]) / 2\n",
    "    ax_top.text(void_center, y_max * 0.95, 'Void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    # Post-void label\n",
    "    post_void_center = (urination_event[1] + x_max) / 2\n",
    "    ax_top.text(post_void_center, y_max * 0.95, 'Post-void', ha='center', va='top', \n",
    "                fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))\n",
    "    \n",
    "    # --- Bottom subplot: Gyroscope ---\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_x'], color='0.2', label='gyr_x', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_y'], color='0.5', label='gyr_y', alpha=0.8)\n",
    "    ax_bottom.plot(imu_data['time'], imu_data['gyr_z'], color='0.7', label='gyr_z', alpha=0.8)\n",
    "    ax_bottom.set_ylabel('Angular Velocity (rad/s)')\n",
    "    ax_bottom.set_xlabel('Time (ms)')\n",
    "    ax_bottom.legend(loc='best')\n",
    "    ax_bottom.grid(True)\n",
    "    \n",
    "    # --- Overlay predictions on bottom subplot ---\n",
    "    ax_pred = ax_bottom.twinx()\n",
    "    predicted_labels = test_results[test_results['group'] == exp_id]['hmm_pred'].tolist()\n",
    "    actual_labels = test_results[test_results['group'] == exp_id]['actual'].tolist()\n",
    "    features_df_ = features_df[features_df['experiment_id'] == exp_id]\n",
    "    print(f\"Experiment ID: {exp_id}; Instance: {void_instance}\")\n",
    "    print(predicted_labels)\n",
    "    plot_predictions_with_timing(features_df_, predicted_labels, ax_pred)\n",
    "    \n",
    "    # Add vertical lines for urination event\n",
    "    ax_bottom.axvline(x=urination_event[0], color='red', linestyle='--', alpha=0.7)\n",
    "    ax_bottom.axvline(x=urination_event[1], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    \n",
    "    path = \"/home/edumaba/Public/MPhil_Thesis/Code/wear_uropatch/classifiers_to_hmm/plots/xgb_5s_0.5/three\"\n",
    "    # Save plot   \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        filename = os.path.join(path, f'three_class{void_instance}({voids[void_instance]})_overlay.png')\n",
    "        plt.savefig(filename)\n",
    "    else:\n",
    "        filename = os.path.join(path, f'three_class{void_instance}({voids[void_instance]})_overlay.png')\n",
    "        plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4163988",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_true = test_results['three_class_actual']\n",
    "hmm_preds = test_results['hmm_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hmm_preds))\n",
    "print(len(three_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['pre-void','void', 'post-void']\n",
    "\n",
    "\n",
    "# Convert back to original labels for the report\n",
    "hmm_preds_original = label_encoder.inverse_transform(hmm_preds)\n",
    "\n",
    "\n",
    "# Generate classification report with actual label names\n",
    "report = classification_report(three_true, hmm_preds_original, labels=classes, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "cm = confusion_matrix(three_true, hmm_preds_original, labels=classes)  # [void, non-void]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap='Blues')\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a86ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a5d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
